{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Work with environments\n",
        "\n",
        "\n",
        "When you run a script as an Azure Machine Learning job, you need to define the execution context for the job run. One key configuration is the compute target on which the script will be run. This could be the local workstation (in this case the compute instance), or a remote compute target such as the Azure Machine Learning managed compute cluster that is provisioned on-demand.\n",
        "\n",
        "In this notebook, you'll create a compute cluster and explore compute targets for jobs.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the  **azure-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-ai-ml\n",
        "!pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-ai-ml in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.24.0)\nRequirement already satisfied: isodate in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.6.1)\nRequirement already satisfied: azure-monitor-opentelemetry in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.6.4)\nRequirement already satisfied: marshmallow>=3.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (3.26.1)\nRequirement already satisfied: azure-mgmt-core>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.4.0)\nRequirement already satisfied: jsonschema>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.23.0)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.12.2)\nRequirement already satisfied: azure-storage-file-datalake>=12.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (12.18.1)\nRequirement already satisfied: strictyaml in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.7.3)\nRequirement already satisfied: pyjwt in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (2.4.0)\nRequirement already satisfied: colorama in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.4.6)\nRequirement already satisfied: azure-storage-file-share in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (12.20.1)\nRequirement already satisfied: azure-storage-blob>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (12.24.1)\nRequirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.1.28)\nRequirement already satisfied: pydash>=6.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (8.0.5)\nRequirement already satisfied: pyyaml>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (6.0.1)\nRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.7.1)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.66.4)\nRequirement already satisfied: azure-core>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.30.2)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.16.0)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (38.0.4)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.19.1)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (2023.12.1)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (24.2.0)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from marshmallow>=3.5->azure-ai-ml) (24.1)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.8.30)\nRequirement already satisfied: azure-core-tracing-opentelemetry~=1.0.0b11 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (1.0.0b11)\nRequirement already satisfied: opentelemetry-instrumentation-psycopg2~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: opentelemetry-instrumentation-urllib3~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: azure-monitor-opentelemetry-exporter~=1.0.0b31 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (1.0.0b33)\nRequirement already satisfied: opentelemetry-instrumentation-fastapi~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: opentelemetry-instrumentation-django~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: opentelemetry-instrumentation-flask~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: opentelemetry-instrumentation-urllib~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: opentelemetry-resource-detector-azure~=0.1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.1.5)\nRequirement already satisfied: opentelemetry-instrumentation-requests~=0.49b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: opentelemetry-sdk~=1.28 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (1.30.0)\nRequirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from strictyaml->azure-ai-ml) (2.9.0.post0)\nRequirement already satisfied: opentelemetry-api<2.0.0,>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (1.30.0)\nRequirement already satisfied: fixedint==0.1.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml) (0.1.6)\nRequirement already satisfied: psutil~=5.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml) (5.9.3)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.16.0)\nRequirement already satisfied: opentelemetry-util-http==0.51b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: opentelemetry-instrumentation-wsgi==0.51b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: opentelemetry-instrumentation==0.51b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.14.1)\nRequirement already satisfied: deprecated>=1.2.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-semantic-conventions==0.51b0->opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.2.14)\nRequirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (8.2.0)\nRequirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: asgiref~=3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (3.8.1)\nRequirement already satisfied: opentelemetry-instrumentation-dbapi==0.51b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation-psycopg2~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (0.51b0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (1.26.19)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.7)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.22)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (3.19.2)\nName: azure-ai-ml\nVersion: 1.24.0\nSummary: Microsoft Azure Machine Learning Client Library for Python\nHome-page: https://github.com/Azure/azure-sdk-for-python\nAuthor: Microsoft Corporation\nAuthor-email: azuresdkengsysadmins@microsoft.com\nLicense: MIT License\nLocation: /anaconda/envs/azureml_py38/lib/python3.10/site-packages\nRequires: azure-common, azure-core, azure-mgmt-core, azure-monitor-opentelemetry, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\nRequired-by: \n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1739184532442
        },
        "vscode": {
          "languageId": "python"
        },
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1739185988058
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1739185991249
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Run a script as a job\n",
        "\n",
        "To train a model, you'll first create the **diabetes_training.py** script in the **src** folder. The script uses the **diabetes.csv** file in the same folder as the training data.\n",
        "\n",
        "Note that you import libraries at the beginning of the script. Functions from these libraries are used to process the data and train the model. Whatever compute you use to run the script must have these libraries installed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/accident-training.py\n",
        "# import libraries\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import joblib\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "def main():\n",
        "    # load the accident dataset\n",
        "    print(\"Loading Data...\")\n",
        "    # Update path to use the mounted dataset\n",
        "    accident = pd.read_csv('accident.csv')\n",
        "    \n",
        "    # drop rows with missing 'Speed_of_Impact' or 'Gender'\n",
        "    accident.dropna(subset=['Speed_of_Impact', 'Gender'], inplace=True)\n",
        "    \n",
        "    # Numeric transformer pipeline\n",
        "    numeric_transformer = make_pipeline(\n",
        "        SimpleImputer(strategy=\"mean\"),\n",
        "        StandardScaler(),\n",
        "    )\n",
        "    \n",
        "    # Categorical transformer pipeline\n",
        "    categorical_transformer = make_pipeline(\n",
        "        SimpleImputer(strategy=\"most_frequent\"),\n",
        "        OneHotEncoder(drop='first')\n",
        "    )\n",
        "    \n",
        "    # Define categorical and numeric columns\n",
        "    cat_columns = ['Gender', 'Helmet_Used', 'Seatbelt_Used']\n",
        "    num_columns = ['Age', 'Speed_of_Impact']\n",
        "    \n",
        "    # Combined feature transformer\n",
        "    features_transformer = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"numeric\", numeric_transformer, num_columns),\n",
        "            (\"categorical\", categorical_transformer, cat_columns),\n",
        "        ],\n",
        "    )\n",
        "    \n",
        "    # Separate features and labels\n",
        "    X = accident[['Age', 'Gender', 'Speed_of_Impact', 'Helmet_Used', 'Seatbelt_Used']]\n",
        "    y = accident['Survived'].values\n",
        "    \n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "    \n",
        "    # Transform train and test data\n",
        "    X_train = features_transformer.fit_transform(X_train)\n",
        "    X_test = features_transformer.transform(X_test)\n",
        "    \n",
        "    # Set regularization hyperparameter\n",
        "    reg = 0.1\n",
        "    \n",
        "    # Train a logistic regression model\n",
        "    print('Training a logistic regression model with regularization rate of', reg)\n",
        "    model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    \n",
        "    # Calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test, y_scores[:, 1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    \n",
        "    # Save the model and transformer\n",
        "    os.makedirs('outputs', exist_ok=True)\n",
        "    joblib.dump(model, 'outputs/model.joblib')\n",
        "    joblib.dump(features_transformer, 'outputs/features.joblib')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/accident-training.py\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1739185920388
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "After you create the script, you can run the script as a job. The script uses common libraries. So you can use a curated environment that includes pandas, numpy, and scikit-learn, among others.\n",
        "\n",
        "The job uses the latest version of the curated environment: `AzureML-sklearn-0.24-ubuntu18.04-py37-cpu`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python accident-training.py\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"captgt0071\",\n",
        "    display_name=\"accident-train-curated-env\",\n",
        "    experiment_name=\"accident-training\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\u001b[32mUploading src (0.53 MBs): 100%|██████████| 525352/525352 [00:00<00:00, 4975446.62it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/green_queen_0jjthl7q2s?wsid=/subscriptions/cda9116f-5326-4a9b-9407-bc3a4391c27c/resourcegroups/rg-dp100-labs/workspaces/gabby102&tid=aef6e45c-850f-4f38-a10b-1df3ad33cdb0\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1739186007326
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "While the job is running, you can already run the next cells."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## List environments\n",
        "\n",
        "Let's explore the environments within the workspace. \n",
        "\n",
        "In the previous job, you used one of the curated environments. To explore all environments that already exist in the workspace, you can list the environments: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "envs = ml_client.environments.list()\n",
        "for env in envs:\n",
        "    print(env.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1739186138670
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Note that all curated environments have names that begin **AzureML-** (you can't use this prefix for your own environments).\n",
        "\n",
        "To review a specific environment, you can retrieve an environment by its name and version. For example, you can retrieve the *description* and *tags* of the curated environment you used for the previous job:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "env = ml_client.environments.get(\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\", version=44)\n",
        "print(env.description, env.tags)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "An environment for tasks such as regression, clustering, and classification with Scikit-learn. Contains the Azure ML SDK and additional python packages. {'Scikit-learn': '0.24.1', 'OS': 'Ubuntu18.04', 'Training': ''}\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1739186517675
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create and use a custom environment\n",
        "\n",
        "If a curated environment doesn't include all the Python packages you need to run your script, you can create your own custom environment. By listing all necessary packages in an environment, you can easily re-run your scripts. All the dependencies are stored in the environment which you can then specify in the job configuration, independent of the compute you use.\n",
        "\n",
        "For example, you can create an environment simply from a Docker image. Certain frameworks like PyTorch will have a public Docker image that already includes everything you need. \n",
        "\n",
        "Let's create an environment from a Docker image:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env_docker_image = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
        "    name=\"docker-image-example\",\n",
        "    description=\"Environment created from a Docker image.\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env_docker_image)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'docker-image-example', 'description': 'Environment created from a Docker image.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/cda9116f-5326-4a9b-9407-bc3a4391c27c/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/gabby102/environments/docker-image-example/versions/1', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/captgt0071/code/Users/captgt007/azure-ml-labs/Labs/04', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fe72e7bb970>, 'serialize': <msrest.serialization.Serializer object at 0x7fe72f294640>, 'version': '1', 'conda_file': None, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1739186682959
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "The environment is now registered in your workspace and you can reference it when you run a script as a job:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python accident-training.py\",\n",
        "    environment=\"docker-image-example:1\",\n",
        "    compute=\"captgt0071\",\n",
        "    display_name=\"accident-train-curated-env\",\n",
        "    experiment_name=\"acident-training\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> The job will quickly fail! Review the error message. </p>\n",
        "\n",
        "The error message will tell you that there is no module named pandas. There are two possible causes for such an error:\n",
        "\n",
        "- The script uses pandas but didn't import the library (`import pandas as pd`). \n",
        "- The script does import the library at the top of the script but the compute didn't have the library installed (`pip install pandas`).\n",
        "\n",
        "After reviewing the `accident-training.py` script you can observe the script is correct, which means the library wasn't installed. In other words, the environment didn't include the necessary packages.\n",
        "\n",
        "Let's create a new environment, using the base Docker image used in the previous job. Now, you'll add a conda specification to ensure the necessary packages will be installed. First, run the following cell to create the conda specification file:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/conda-env.yml\n",
        "name: basic-env-cpu\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.11\n",
        "  - scikit-learn\n",
        "  - pandas\n",
        "  - numpy\n",
        "  - matplotlib"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing src/conda-env.yml\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Note that all necessary dependencies are included in the conda specification file for the script to run successfully.\n",
        "\n",
        "Create a new environment using the base Docker image **and** the conda specification file to add the necessary dependencies. Azure Machine Learning will build the conda environment on top of the Docker image you provided. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env_docker_conda = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
        "    conda_file=\"./src/conda-env.yml\",\n",
        "    name=\"docker-image-plus-conda-example\",\n",
        "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env_docker_conda)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'docker-image-plus-conda-example', 'description': 'Environment created from a Docker image plus Conda environment.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/cda9116f-5326-4a9b-9407-bc3a4391c27c/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/gabby102/environments/docker-image-plus-conda-example/versions/1', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/captgt0071/code/Users/captgt007/azure-ml-labs/Labs/04', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fe711476890>, 'serialize': <msrest.serialization.Serializer object at 0x7fe72b748a00>, 'version': '1', 'conda_file': {'channels': ['conda-forge'], 'dependencies': ['python=3.11', 'scikit-learn', 'pandas', 'numpy', 'matplotlib'], 'name': 'basic-env-cpu'}, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"conda-forge\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.11\",\\n    \"scikit-learn\",\\n    \"pandas\",\\n    \"numpy\",\\n    \"matplotlib\"\\n  ],\\n  \"name\": \"basic-env-cpu\"\\n}'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1739187210319
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Now, you can submit a job with the new environment to run the script:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python accident-training.py\",\n",
        "    environment=\"docker-image-plus-conda-example:1\",\n",
        "    compute=\"captgt0071\",\n",
        "    display_name=\"accident-train-custom-env\",\n",
        "    experiment_name=\"accident-training\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/strong_apricot_77nl373q3s?wsid=/subscriptions/cda9116f-5326-4a9b-9407-bc3a4391c27c/resourcegroups/rg-dp100-labs/workspaces/gabby102&tid=aef6e45c-850f-4f38-a10b-1df3ad33cdb0\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1739187351682
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Submitting the job with the new custom environment triggers the build of the environment. The first time you use a newly created environment, it can take 10-15 minutes to build the environment, which also means your job will take longer to complete. \n",
        "\n",
        "You can also choose to manually trigger the build of the environment before you submit a job. The environment only needs to be built the first time you use it. \n",
        "\n",
        "When the job triggers the build of a new environment, you can review the logs of the build in the **Outputs + logs** tab of the job. Open **azureml-logs/20_image_build_log.txt** to inspect the logs of the environment build. \n",
        "\n",
        "![Screenshot build logs](./images/screenshot-logs.png)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}