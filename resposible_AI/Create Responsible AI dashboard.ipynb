{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Create a responsible AI dashboard to evaluate your models\n",
        "\n",
        "When you compare and evaluate your machine learning models, you'll want to review more than just their performance metric. Azure Machine Learning allows you to create responsible AI dashboard to explore how the model performs on different cohorts of the data. "
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Prepare the data\n",
        "\n",
        "To create the responsible AI dashboard, you'll need a training and test dataset, stored as Parquet files and registered as data assets.\n",
        "\n",
        "The data is currently stored as CSV files. Let's convert them to Parquet files. \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting azure-ai-ml\n  Downloading azure_ai_ml-1.25.0-py3-none-any.whl (12.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hCollecting pydash>=6.0.0\n  Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.66.4)\nRequirement already satisfied: azure-storage-blob>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (12.13.0)\nRequirement already satisfied: pyjwt in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (2.4.0)\nCollecting azure-storage-file-datalake>=12.2.0\n  Downloading azure_storage_file_datalake-12.18.1-py3-none-any.whl (258 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting strictyaml\n  Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: isodate in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.6.1)\nRequirement already satisfied: pyyaml>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (6.0.1)\nRequirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.1.28)\nCollecting azure-storage-file-share\n  Downloading azure_storage_file_share-12.20.1-py3-none-any.whl (286 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.4/286.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: colorama in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.4.6)\nRequirement already satisfied: azure-core>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.30.2)\nCollecting azure-monitor-opentelemetry\n  Downloading azure_monitor_opentelemetry-1.6.4-py3-none-any.whl (23 kB)\nRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.7.1)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.12.2)\nCollecting marshmallow>=3.5\n  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: azure-mgmt-core>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.4.0)\nRequirement already satisfied: jsonschema>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.23.0)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.16.0)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (38.0.4)\nCollecting azure-storage-blob>=12.10.0\n  Downloading azure_storage_blob-12.24.1-py3-none-any.whl (408 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.35.1)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (24.2.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.19.1)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from marshmallow>=3.5->azure-ai-ml) (24.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.8.30)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2.0.0)\nCollecting opentelemetry-sdk~=1.28\n  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-instrumentation-fastapi~=0.49b0\n  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\nCollecting opentelemetry-instrumentation-urllib~=0.49b0\n  Downloading opentelemetry_instrumentation_urllib-0.51b0-py3-none-any.whl (12 kB)\nCollecting azure-monitor-opentelemetry-exporter~=1.0.0b31\n  Downloading azure_monitor_opentelemetry_exporter-1.0.0b33-py2.py3-none-any.whl (151 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-instrumentation-urllib3~=0.49b0\n  Downloading opentelemetry_instrumentation_urllib3-0.51b0-py3-none-any.whl (12 kB)\nCollecting opentelemetry-resource-detector-azure~=0.1.4\n  Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl (14 kB)\nCollecting opentelemetry-instrumentation-django~=0.49b0\n  Downloading opentelemetry_instrumentation_django-0.51b0-py3-none-any.whl (19 kB)\nCollecting opentelemetry-instrumentation-flask~=0.49b0\n  Downloading opentelemetry_instrumentation_flask-0.51b0-py3-none-any.whl (14 kB)\nCollecting opentelemetry-instrumentation-psycopg2~=0.49b0\n  Downloading opentelemetry_instrumentation_psycopg2-0.51b0-py3-none-any.whl (10 kB)\nCollecting opentelemetry-instrumentation-requests~=0.49b0\n  Downloading opentelemetry_instrumentation_requests-0.51b0-py3-none-any.whl (12 kB)\nCollecting azure-core-tracing-opentelemetry~=1.0.0b11\n  Downloading azure_core_tracing_opentelemetry-1.0.0b11-py3-none-any.whl (10 kB)\nRequirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from strictyaml->azure-ai-ml) (2.9.0.post0)\nRequirement already satisfied: opentelemetry-api<2.0.0,>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (1.26.0)\nRequirement already satisfied: psutil~=5.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml) (5.9.3)\nCollecting fixedint==0.1.6\n  Downloading fixedint-0.1.6-py3-none-any.whl (12 kB)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.16.0)\nCollecting opentelemetry-instrumentation==0.51b0\n  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\nCollecting opentelemetry-semantic-conventions==0.51b0\n  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-instrumentation-wsgi==0.51b0\n  Downloading opentelemetry_instrumentation_wsgi-0.51b0-py3-none-any.whl (14 kB)\nCollecting opentelemetry-util-http==0.51b0\n  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.14.1)\nRequirement already satisfied: deprecated>=1.2.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-semantic-conventions==0.51b0->opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.2.14)\nCollecting opentelemetry-api<2.0.0,>=1.12.0\n  Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (8.2.0)\nCollecting opentelemetry-instrumentation-asgi==0.51b0\n  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\nCollecting asgiref~=3.0\n  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nCollecting opentelemetry-instrumentation-dbapi==0.51b0\n  Downloading opentelemetry_instrumentation_dbapi-0.51b0-py3-none-any.whl (12 kB)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (1.26.19)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.3.2)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.22)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (3.19.2)\nInstalling collected packages: fixedint, pydash, opentelemetry-util-http, marshmallow, asgiref, strictyaml, opentelemetry-api, opentelemetry-semantic-conventions, azure-storage-file-share, azure-storage-blob, azure-core-tracing-opentelemetry, opentelemetry-sdk, opentelemetry-instrumentation, azure-storage-file-datalake, opentelemetry-resource-detector-azure, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-asgi, azure-monitor-opentelemetry-exporter, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-django, azure-monitor-opentelemetry, azure-ai-ml\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.26.0\n    Uninstalling opentelemetry-api-1.26.0:\n      Successfully uninstalled opentelemetry-api-1.26.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.47b0\n    Uninstalling opentelemetry-semantic-conventions-0.47b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.47b0\n  Attempting uninstall: azure-storage-blob\n    Found existing installation: azure-storage-blob 12.13.0\n    Uninstalling azure-storage-blob-12.13.0:\n      Successfully uninstalled azure-storage-blob-12.13.0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.26.0\n    Uninstalling opentelemetry-sdk-1.26.0:\n      Successfully uninstalled opentelemetry-sdk-1.26.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmlflow-skinny 2.15.0 requires importlib-metadata!=4.7.0,<8,>=3.7.0, but you have importlib-metadata 8.2.0 which is incompatible.\nazureml-mlflow 1.57.0 requires azure-storage-blob<=12.19.0,>=12.5.0, but you have azure-storage-blob 12.24.1 which is incompatible.\nadlfs 2024.7.0 requires fsspec>=2023.12.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.8.1 azure-ai-ml-1.25.0 azure-core-tracing-opentelemetry-1.0.0b11 azure-monitor-opentelemetry-1.6.4 azure-monitor-opentelemetry-exporter-1.0.0b33 azure-storage-blob-12.24.1 azure-storage-file-datalake-12.18.1 azure-storage-file-share-12.20.1 fixedint-0.1.6 marshmallow-3.26.1 opentelemetry-api-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-dbapi-0.51b0 opentelemetry-instrumentation-django-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-instrumentation-flask-0.51b0 opentelemetry-instrumentation-psycopg2-0.51b0 opentelemetry-instrumentation-requests-0.51b0 opentelemetry-instrumentation-urllib-0.51b0 opentelemetry-instrumentation-urllib3-0.51b0 opentelemetry-instrumentation-wsgi-0.51b0 opentelemetry-resource-detector-azure-0.1.5 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 pydash-8.0.5 strictyaml-1.7.3\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read training and test dataset\n",
        "df_training = pd.read_csv(\"train-data/diabetes.csv\")\n",
        "df_test = pd.read_csv(\"test-data/diabetes-test.csv\")\n",
        "\n",
        "# display the first few rows of the training dataset\n",
        "df_training.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "   Pregnancies  PlasmaGlucose  DiastolicBloodPressure  TricepsThickness  \\\n0            0            171                      80                34   \n1            8             92                      93                47   \n2            7            115                      47                52   \n3            9            103                      78                25   \n4            1             85                      59                27   \n\n   SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n0            23  43.509726          1.213191   21         0  \n1            36  21.240576          0.158365   23         0  \n2            35  41.511523          0.079019   23         0  \n3           304  29.582192          1.282870   43         1  \n4            35  42.604536          0.549542   22         0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>PlasmaGlucose</th>\n      <th>DiastolicBloodPressure</th>\n      <th>TricepsThickness</th>\n      <th>SerumInsulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigree</th>\n      <th>Age</th>\n      <th>Diabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>171</td>\n      <td>80</td>\n      <td>34</td>\n      <td>23</td>\n      <td>43.509726</td>\n      <td>1.213191</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>92</td>\n      <td>93</td>\n      <td>47</td>\n      <td>36</td>\n      <td>21.240576</td>\n      <td>0.158365</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>115</td>\n      <td>47</td>\n      <td>52</td>\n      <td>35</td>\n      <td>41.511523</td>\n      <td>0.079019</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>103</td>\n      <td>78</td>\n      <td>25</td>\n      <td>304</td>\n      <td>29.582192</td>\n      <td>1.282870</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>85</td>\n      <td>59</td>\n      <td>27</td>\n      <td>35</td>\n      <td>42.604536</td>\n      <td>0.549542</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1739386261222
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# convert data to table\n",
        "table_training = pa.Table.from_pandas(df_training)\n",
        "table_test = pa.Table.from_pandas(df_test)\n",
        "\n",
        "# write tables out to parquet\n",
        "pq.write_table(table_training, \"train-data/diabetes-training.parquet\", version=\"1.0\")\n",
        "pq.write_table(table_test, \"test-data/diabetes-test.parquet\", version=\"1.0\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1739386299347
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Before you continue\n",
        "\n",
        "You'll need the latest version of the **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azure-ai-ml\nVersion: 1.25.0\nSummary: Microsoft Azure Machine Learning Client Library for Python\nHome-page: https://github.com/Azure/azure-sdk-for-python\nAuthor: Microsoft Corporation\nAuthor-email: azuresdkengsysadmins@microsoft.com\nLicense: MIT License\nLocation: /anaconda/envs/azureml_py38/lib/python3.10/site-packages\nRequires: azure-common, azure-core, azure-mgmt-core, azure-monitor-opentelemetry, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\nRequired-by: \nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1739386352184
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1739386630497
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1739386635963
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create the data assets\n",
        "\n",
        "To create the responsible AI dashboard, you need to register the training and testing datasets as **MLtable** data assets. The MLtable data assets reference the Parquet files you created earlier."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"train-data/\"\n",
        "test_data_path = \"test-data/\"\n",
        "data_version = \"1\""
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1739386697630
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "input_train_data = \"diabetes_train_mltable\"\n",
        "input_test_data = \"diabetes_test_mltable\"\n",
        "\n",
        "try:\n",
        "    # Try getting data already registered in workspace\n",
        "    train_data = ml_client.data.get(\n",
        "        name=input_train_data,\n",
        "        version=data_version,\n",
        "    )\n",
        "    test_data = ml_client.data.get(\n",
        "        name=input_test_data,\n",
        "        version=data_version,\n",
        "    )\n",
        "except Exception as e:\n",
        "    train_data = Data(\n",
        "        path=train_data_path,\n",
        "        type=AssetTypes.MLTABLE,\n",
        "        description=\"RAI diabetes training data\",\n",
        "        name=input_train_data,\n",
        "        version=data_version,\n",
        "    )\n",
        "    ml_client.data.create_or_update(train_data)\n",
        "\n",
        "    test_data = Data(\n",
        "        path=test_data_path,\n",
        "        type=AssetTypes.MLTABLE,\n",
        "        description=\"RAI diabetes test data\",\n",
        "        name=input_test_data,\n",
        "        version=data_version,\n",
        "    )\n",
        "    ml_client.data.create_or_update(test_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading train-data (0.7 MBs): 100%|██████████| 698594/698594 [00:00<00:00, 16301513.86it/s]\n\u001b[39m\n\n\u001b[32mUploading test-data (0.35 MBs): 100%|██████████| 353392/353392 [00:00<00:00, 10389681.20it/s]\n\u001b[39m\n\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1739386730767
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Build the pipeline to create the responsible AI dashboard\n",
        "\n",
        "To create the dashboard, you'll build a pipeline with prebuilt components that are registered by default in the Azure Machine Learning workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get handle to azureml registry for the RAI built in components\n",
        "registry_name = \"azureml\"\n",
        "ml_client_registry = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group_name=ml_client.resource_group_name,\n",
        "    registry_name=registry_name,\n",
        ")\n",
        "print(ml_client_registry)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Overriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f975f8c82b0>,\n         subscription_id=6c6683e9-e5fe-4038-8519-ce6ebec2ba15,\n         resource_group_name=registry-builtin-prod-eastus-01,\n         workspace_name=None)\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1739386752248
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Register the model\n",
        "\n",
        "A machine learning model has already been trained. The model predicts whether a patient has diabetes. All model files are stored in the `model` folder. \n",
        "\n",
        "Register the model by pointing to the `model` folder and its contents."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "file_model = Model(\n",
        "    path=\"model\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    name=\"local-mlflow-diabetes\",\n",
        "    description=\"Model created from local file.\",\n",
        ")\n",
        "model = ml_client.models.create_or_update(file_model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading model (0.0 MBs):   0%|          | 0/2296 [00:00<?, ?it/s]\r\u001b[32mUploading model (0.0 MBs): 100%|██████████| 2296/2296 [00:00<00:00, 50946.02it/s]\n\u001b[39m\n\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1739386820754
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Build the pipeline\n",
        "\n",
        "To create the responsible AI dashboard, you'll create a pipeline using the prebuilt components. You can choose which components to use, and which features you want to include in your dashboard. You'll create a dashboard that includes error analysis and model interpretability. \n",
        "\n",
        "Next to the responsible AI features, a pipeline to build a dashboard needs to include a component at the start to construct the dashboard, and a component at the end to gather all generated insights."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = model.name\n",
        "expected_model_id = f\"{model_name}:1\"\n",
        "azureml_model_id = f\"azureml:{expected_model_id}\"\n",
        "azureml_model_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "'azureml:local-mlflow-diabetes:1'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1739386873576
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = \"latest\"\n",
        "\n",
        "rai_constructor_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\n",
        ")\n",
        "\n",
        "# we get latest version and use the same version for all components\n",
        "version = rai_constructor_component.version\n",
        "print(\"The current version of RAI built-in components is: \" + version)\n",
        "\n",
        "rai_erroranalysis_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\n",
        ")\n",
        "\n",
        "rai_explanation_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\n",
        ")\n",
        "\n",
        "rai_gather_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The current version of RAI built-in components is: 0.17.0\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1739387439571
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "When you've retrieved all components you want to use, you can build the pipeline and connect the components in the appropriate order:\n",
        "\n",
        "1. Construct the dashboard.\n",
        "1. Add error analysis.\n",
        "1. Add explanations.\n",
        "1. Gather all insights and visualize them in the dashboard."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "azureml_model_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "'azureml:local-mlflow-diabetes:1'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1739387545408
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739387596474
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input, dsl\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "compute_name = \"captgt0071\"\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=compute_name,\n",
        "    description=\"RAI insights on diabetes data\",\n",
        "    experiment_name=f\"RAI_insights_{model_name}\",\n",
        ")\n",
        "def rai_decision_pipeline(\n",
        "    target_column_name, train_data, test_data\n",
        "):\n",
        "    # Initiate the RAIInsights\n",
        "    create_rai_job = rai_constructor_component(\n",
        "        title=\"RAI dashboard diabetes\",\n",
        "        task_type=\"classification\",\n",
        "        model_info=expected_model_id,\n",
        "        model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n",
        "        train_dataset=train_data,\n",
        "        test_dataset=test_data,\n",
        "        target_column_name=target_column_name,\n",
        "    )\n",
        "    create_rai_job.set_limits(timeout=300)\n",
        "\n",
        "    # Add error analysis\n",
        "    error_job = rai_erroranalysis_component(\n",
        "        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
        "    )\n",
        "    error_job.set_limits(timeout=300)\n",
        "\n",
        "    # Add explanations\n",
        "    explanation_job = rai_explanation_component(\n",
        "        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
        "        comment=\"add explanation\", \n",
        "    )\n",
        "    explanation_job.set_limits(timeout=300)\n",
        "\n",
        "    # Combine everything\n",
        "    rai_gather_job = rai_gather_component(\n",
        "        constructor=create_rai_job.outputs.rai_insights_dashboard,\n",
        "        insight_3=error_job.outputs.error_analysis,\n",
        "        insight_4=explanation_job.outputs.explanation,\n",
        "    )\n",
        "    rai_gather_job.set_limits(timeout=300)\n",
        "\n",
        "    rai_gather_job.outputs.dashboard.mode = \"upload\"\n",
        "\n",
        "    return {\n",
        "        \"dashboard\": rai_gather_job.outputs.dashboard,\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1739387748536
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Now the pipeline has been built, you need to define the two necessary inputs: the training and test dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input\n",
        "target_feature = \"Diabetic\"\n",
        "\n",
        "diabetes_train_pq = Input(\n",
        "    type=\"mltable\",\n",
        "    path=f\"azureml:{input_train_data}:{data_version}\",\n",
        "    mode=\"download\",\n",
        ")\n",
        "diabetes_test_pq = Input(\n",
        "    type=\"mltable\",\n",
        "    path=f\"azureml:{input_test_data}:{data_version}\",\n",
        "    mode=\"download\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1739387774562
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Finally, we'll put everything together: assign the inputs to the pipeline and set the target column (the predicted label)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from azure.ai.ml import Output\n",
        "\n",
        "# Pipeline to construct the RAI Insights\n",
        "insights_pipeline_job = rai_decision_pipeline(\n",
        "    target_column_name=\"Diabetic\",\n",
        "    train_data=diabetes_train_pq,\n",
        "    test_data=diabetes_test_pq,\n",
        ")\n",
        "\n",
        "# Workaround to enable the download\n",
        "rand_path = str(uuid.uuid4())\n",
        "insights_pipeline_job.outputs.dashboard = Output(\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\n",
        "    mode=\"upload\",\n",
        "    type=\"uri_folder\",\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1739387841174
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Run the pipeline\n",
        "\n",
        "When you've successfully built the pipeline, you can submit it. The following code will submit the pipeline and check the status of the pipeline. You can also view the pipeline's status in the studio. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import PipelineJob\n",
        "from IPython.core.display import HTML\n",
        "from IPython.display import display\n",
        "import time\n",
        "\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
        "    assert created_job is not None\n",
        "\n",
        "    print(\"Pipeline job can be accessed in the following URL:\")\n",
        "    display(HTML('<a href=\"{0}\">{0}</a>'.format(created_job.studio_url)))\n",
        "\n",
        "    while created_job.status not in [\n",
        "        \"Completed\",\n",
        "        \"Failed\",\n",
        "        \"Canceled\",\n",
        "        \"NotResponding\",\n",
        "    ]:\n",
        "        time.sleep(30)\n",
        "        created_job = ml_client.jobs.get(created_job.name)\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\n",
        "    assert created_job.status == \"Completed\"\n",
        "    return created_job\n",
        "\n",
        "\n",
        "# This is the actual submission\n",
        "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline job can be accessed in the following URL:\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<a href=\"https://ml.azure.com/runs/jovial_cherry_z3nkpqxwp6?wsid=/subscriptions/cda9116f-5326-4a9b-9407-bc3a4391c27c/resourcegroups/mlw-dp100/workspaces/mlw-dp100-labs&tid=aef6e45c-850f-4f38-a10b-1df3ad33cdb0\">https://ml.azure.com/runs/jovial_cherry_z3nkpqxwp6?wsid=/subscriptions/cda9116f-5326-4a9b-9407-bc3a4391c27c/resourcegroups/mlw-dp100/workspaces/mlw-dp100-labs&tid=aef6e45c-850f-4f38-a10b-1df3ad33cdb0</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1677026340892
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "When the pipeline is completed, you can review the dashboard in the studio. "
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}