{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Train a classification model with Automated Machine Learning\n",
        "\n",
        "There are many kinds of machine learning algorithm that you can use to train a model, and sometimes it's not easy to determine the most effective algorithm for your particular data and prediction requirements. Additionally, you can significantly affect the predictive performance of a model by preprocessing the training data, using techniques such as normalization, missing feature imputation, and others. In your quest to find the best model for your requirements, you may need to try many combinations of algorithms and preprocessing transformations; which takes a lot of time and compute resources.\n",
        "\n",
        "Azure Machine Learning enables you to automate the comparison of models trained using different algorithms and preprocessing options. You can use the visual interface in [Azure Machine Learning Studio](https://ml/azure.com) or the Python SDK (v2) to leverage this capability. The Python SDK gives you greater control over the settings for the automated machine learning job, but the visual interface is easier to use.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the  **azure-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-ai-ml\n",
        "!pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting azure-ai-ml\n  Downloading azure_ai_ml-1.24.0-py3-none-any.whl (12.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: isodate in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.6.1)\nRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.7.1)\nRequirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.1.28)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.12.2)\nRequirement already satisfied: azure-core>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.30.2)\nCollecting azure-storage-file-datalake>=12.2.0\n  Downloading azure_storage_file_datalake-12.18.1-py3-none-any.whl (258 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: jsonschema>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.23.0)\nCollecting azure-monitor-opentelemetry\n  Downloading azure_monitor_opentelemetry-1.6.4-py3-none-any.whl (23 kB)\nCollecting marshmallow>=3.5\n  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: colorama in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.4.6)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.66.4)\nRequirement already satisfied: azure-storage-blob>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (12.13.0)\nCollecting pydash>=6.0.0\n  Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (6.0.1)\nCollecting strictyaml\n  Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyjwt in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (2.4.0)\nCollecting azure-storage-file-share\n  Downloading azure_storage_file_share-12.20.1-py3-none-any.whl (286 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.4/286.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: azure-mgmt-core>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.4.0)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.16.0)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (38.0.4)\nCollecting azure-storage-blob>=12.10.0\n  Downloading azure_storage_blob-12.24.1-py3-none-any.whl (408 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.19.1)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (24.2.0)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from marshmallow>=3.5->azure-ai-ml) (24.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.8.30)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2.0.0)\nCollecting opentelemetry-instrumentation-django~=0.49b0\n  Downloading opentelemetry_instrumentation_django-0.51b0-py3-none-any.whl (19 kB)\nCollecting azure-core-tracing-opentelemetry~=1.0.0b11\n  Downloading azure_core_tracing_opentelemetry-1.0.0b11-py3-none-any.whl (10 kB)\nCollecting opentelemetry-instrumentation-fastapi~=0.49b0\n  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\nCollecting opentelemetry-instrumentation-urllib3~=0.49b0\n  Downloading opentelemetry_instrumentation_urllib3-0.51b0-py3-none-any.whl (12 kB)\nCollecting opentelemetry-instrumentation-requests~=0.49b0\n  Downloading opentelemetry_instrumentation_requests-0.51b0-py3-none-any.whl (12 kB)\nCollecting azure-monitor-opentelemetry-exporter~=1.0.0b31\n  Downloading azure_monitor_opentelemetry_exporter-1.0.0b33-py2.py3-none-any.whl (151 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-instrumentation-flask~=0.49b0\n  Downloading opentelemetry_instrumentation_flask-0.51b0-py3-none-any.whl (14 kB)\nCollecting opentelemetry-instrumentation-urllib~=0.49b0\n  Downloading opentelemetry_instrumentation_urllib-0.51b0-py3-none-any.whl (12 kB)\nCollecting opentelemetry-sdk~=1.28\n  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-resource-detector-azure~=0.1.4\n  Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl (14 kB)\nCollecting opentelemetry-instrumentation-psycopg2~=0.49b0\n  Downloading opentelemetry_instrumentation_psycopg2-0.51b0-py3-none-any.whl (10 kB)\nRequirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from strictyaml->azure-ai-ml) (2.9.0.post0)\nRequirement already satisfied: opentelemetry-api<2.0.0,>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (1.26.0)\nCollecting fixedint==0.1.6\n  Downloading fixedint-0.1.6-py3-none-any.whl (12 kB)\nRequirement already satisfied: psutil~=5.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml) (5.9.3)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.16.0)\nCollecting opentelemetry-instrumentation==0.51b0\n  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\nCollecting opentelemetry-semantic-conventions==0.51b0\n  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-util-http==0.51b0\n  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\nCollecting opentelemetry-instrumentation-wsgi==0.51b0\n  Downloading opentelemetry_instrumentation_wsgi-0.51b0-py3-none-any.whl (14 kB)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.14.1)\nCollecting opentelemetry-api<2.0.0,>=1.12.0\n  Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: deprecated>=1.2.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-semantic-conventions==0.51b0->opentelemetry-instrumentation-django~=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.2.14)\nRequirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (8.2.0)\nCollecting opentelemetry-instrumentation-asgi==0.51b0\n  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\nCollecting asgiref~=3.0\n  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nCollecting opentelemetry-instrumentation-dbapi==0.51b0\n  Downloading opentelemetry_instrumentation_dbapi-0.51b0-py3-none-any.whl (12 kB)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (1.26.19)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.7)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.22)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (3.19.2)\nInstalling collected packages: fixedint, pydash, opentelemetry-util-http, marshmallow, asgiref, strictyaml, opentelemetry-api, opentelemetry-semantic-conventions, azure-storage-file-share, azure-storage-blob, azure-core-tracing-opentelemetry, opentelemetry-sdk, opentelemetry-instrumentation, azure-storage-file-datalake, opentelemetry-resource-detector-azure, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-asgi, azure-monitor-opentelemetry-exporter, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-django, azure-monitor-opentelemetry, azure-ai-ml\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.26.0\n    Uninstalling opentelemetry-api-1.26.0:\n      Successfully uninstalled opentelemetry-api-1.26.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.47b0\n    Uninstalling opentelemetry-semantic-conventions-0.47b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.47b0\n  Attempting uninstall: azure-storage-blob\n    Found existing installation: azure-storage-blob 12.13.0\n    Uninstalling azure-storage-blob-12.13.0:\n      Successfully uninstalled azure-storage-blob-12.13.0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.26.0\n    Uninstalling opentelemetry-sdk-1.26.0:\n      Successfully uninstalled opentelemetry-sdk-1.26.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmlflow-skinny 2.15.0 requires importlib-metadata!=4.7.0,<8,>=3.7.0, but you have importlib-metadata 8.2.0 which is incompatible.\nazureml-mlflow 1.57.0 requires azure-storage-blob<=12.19.0,>=12.5.0, but you have azure-storage-blob 12.24.1 which is incompatible.\nadlfs 2024.7.0 requires fsspec>=2023.12.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.8.1 azure-ai-ml-1.24.0 azure-core-tracing-opentelemetry-1.0.0b11 azure-monitor-opentelemetry-1.6.4 azure-monitor-opentelemetry-exporter-1.0.0b33 azure-storage-blob-12.24.1 azure-storage-file-datalake-12.18.1 azure-storage-file-share-12.20.1 fixedint-0.1.6 marshmallow-3.26.1 opentelemetry-api-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-dbapi-0.51b0 opentelemetry-instrumentation-django-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-instrumentation-flask-0.51b0 opentelemetry-instrumentation-psycopg2-0.51b0 opentelemetry-instrumentation-requests-0.51b0 opentelemetry-instrumentation-urllib-0.51b0 opentelemetry-instrumentation-urllib3-0.51b0 opentelemetry-instrumentation-wsgi-0.51b0 opentelemetry-resource-detector-azure-0.1.5 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 pydash-8.0.5 strictyaml-1.7.3\nName: azure-ai-ml\nVersion: 1.24.0\nSummary: Microsoft Azure Machine Learning Client Library for Python\nHome-page: https://github.com/Azure/azure-sdk-for-python\nAuthor: Microsoft Corporation\nAuthor-email: azuresdkengsysadmins@microsoft.com\nLicense: MIT License\nLocation: /anaconda/envs/azureml_py38/lib/python3.10/site-packages\nRequires: azure-common, azure-core, azure-mgmt-core, azure-monitor-opentelemetry, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\nRequired-by: \n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1739273922529
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1739273926532
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "\n",
        "You don't need to create a training script for automated machine learning, but you do need to load the training data. \n",
        "\n",
        "In this case, I use a dataset containing details of accident victims. \n",
        "\n",
        "To pass a dataset as an input to an automated machine learning job, the data must be in tabular form and include a target column. For the data to be interpreted as a tabular dataset, the input dataset must be a **MLTable**.\n",
        "\n",
        "A MLTable data asset will be created during set-up. You can explore the data asset by navigating to the **Data** page. You'll retrieve the data asset here by specifying its name  and version `1`. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('accident.csv')\n",
        "data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "   Age  Gender  Speed_of_Impact Helmet_Used Seatbelt_Used  Survived\n0   56  Female             27.0          No            No         1\n1   69  Female             46.0          No           Yes         1\n2   46    Male             46.0         Yes           Yes         0\n3   32    Male            117.0          No           Yes         0\n4   60  Female             40.0         Yes           Yes         0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Speed_of_Impact</th>\n      <th>Helmet_Used</th>\n      <th>Seatbelt_Used</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>Female</td>\n      <td>27.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>69</td>\n      <td>Female</td>\n      <td>46.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46</td>\n      <td>Male</td>\n      <td>46.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32</td>\n      <td>Male</td>\n      <td>117.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>Female</td>\n      <td>40.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1739274079830
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "local_path = './'\n",
        "\n",
        "my_data = Data(\n",
        "    path=local_path,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"MLTable pointing to accident.csv in the folder\",\n",
        "    name=\"accident-training\"   \n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading 06 (5.66 MBs):   0%|          | 0/5664955 [00:00<?, ?it/s]\r\u001b[32mUploading 06 (5.66 MBs): 100%|██████████| 5664955/5664955 [00:00<00:00, 38034578.37it/s]\r\u001b[32mUploading 06 (5.66 MBs): 100%|██████████| 5664955/5664955 [00:00<00:00, 37743365.94it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "Data({'path': 'azureml://subscriptions/cda9116f-5326-4a9b-9407-bc3a4391c27c/resourcegroups/rg-dp100/workspaces/gabbyworkout/datastores/workspaceblobstore/paths/LocalUpload/a70919a9c0826f32cdb2fac14909a725/06/', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': ['./accident.csv'], 'type': 'mltable', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'accident-training', 'description': 'MLTable pointing to accident.csv in the folder', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/cda9116f-5326-4a9b-9407-bc3a4391c27c/resourceGroups/rg-dp100/providers/Microsoft.MachineLearningServices/workspaces/gabbyworkout/data/accident-training/versions/1', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/captgt0071/code/Users/captgt007/azure-ml-labs/Labs/06', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f924d287b20>, 'serialize': <msrest.serialization.Serializer object at 0x7f924d2ccf10>, 'version': '1', 'latest_version': None, 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1739274224562
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "# creates a dataset based on the files in the local data folder\n",
        "my_training_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml:accident-training:1\")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1739274299803
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_training_data_input"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "{'type': 'mltable', 'path': 'azureml:accident-training:1'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1739274552973
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Configure automated machine learning job\n",
        "\n",
        "Now, you're ready to configure the automated machine learning experiment.\n",
        "\n",
        "When you run the code below, it will create an automated machine learning job that:\n",
        "\n",
        "- Uses the compute cluster named `captgt0071`\n",
        "- Sets `survived` as the target column\n",
        "- Sets `accuracy` as the primary metric\n",
        "- Times out after `60` minutes of total training time \n",
        "- Trains a maximum of `5` models\n",
        "- No model will be trained with the `LogisticRegression` algorithm"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import automl\n",
        "\n",
        "# configure the classification job\n",
        "classification_job = automl.classification(\n",
        "    compute=\"captgt0071\",\n",
        "    experiment_name=\"auto-ml-class-dev\",\n",
        "    training_data=my_training_data_input,\n",
        "    target_column_name=\"Survived\",\n",
        "    primary_metric=\"accuracy\",\n",
        "    n_cross_validations=5,\n",
        "    enable_model_explainability=True\n",
        ")\n",
        "\n",
        "# set the limits (optional)\n",
        "classification_job.set_limits(\n",
        "    timeout_minutes=60, \n",
        "    trial_timeout_minutes=20, \n",
        "    max_trials=5,\n",
        "    enable_early_termination=True,\n",
        ")\n",
        "\n",
        "# set the training properties (optional)\n",
        "classification_job.set_training(\n",
        "    blocked_training_algorithms=[\"LogisticRegression\"], \n",
        "    enable_onnx_compatible_models=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1739274577589
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Run an automated machine learning job\n",
        "\n",
        "OK, you're ready to go. Let's run the automated machine learning experiment.\n",
        "\n",
        "> **Note**: This may take some time!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit the AutoML job\n",
        "returned_job = ml_client.jobs.create_or_update(\n",
        "    classification_job\n",
        ")  \n",
        "\n",
        "# submit the job to the backend\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/lemon_feijoa_vnnqbxhh83?wsid=/subscriptions/cda9116f-5326-4a9b-9407-bc3a4391c27c/resourcegroups/rg-dp100/workspaces/gabbyworkout&tid=aef6e45c-850f-4f38-a10b-1df3ad33cdb0\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1739274594877
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "While the job is running, you can monitor it in the Studio."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}